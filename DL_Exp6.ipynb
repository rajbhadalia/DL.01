{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DL-Exp6",
      "provenance": [],
      "authorship_tag": "ABX9TyOSXZq0MKvYlBnigUpMWVmo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rajbhadalia/DL.01/blob/exp1/DL_Exp6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qqeupBpN-UC-"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import cv2\n",
        "import PIL.Image\n",
        "import urllib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "import keras\n",
        "from keras.datasets import cifar10, cifar100, mnist, fashion_mnist\n",
        "from keras.utils import to_categorical\n",
        "from keras import models, layers\n",
        "from keras.models import Sequential, load_model, Model\n",
        "from keras.layers import Dense, Flatten, Conv2D, Dropout, Activation, MaxPooling2D, Input\n",
        "from keras.optimizers import SGD\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "\n",
        "from keras.applications.vgg16 import VGG16, preprocess_input\n",
        "from keras.applications.vgg19 import VGG19, preprocess_input"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XzzOFXQgj4yn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d13255a-c774-499e-b894-17e6b2194ca8"
      },
      "source": [
        "# !unzip '/content/drive/MyDrive/Colab Notebooks/Deep Learning/Colab new.zip'\n",
        "!unzip Colab.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "unzip:  cannot find or open Colab.zip, Colab.zip.zip or Colab.zip.ZIP.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aqZ0bQy3-UC_"
      },
      "source": [
        "## Loading The Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xrhpuLvJ-UC_"
      },
      "source": [
        "### Importing Train Data From CIFAR10"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-tLqZcy5-UDA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "baf46e5a-4fe0-4e26-eaea-003da31af5c0"
      },
      "source": [
        "(c10x_train, c10y_train), (c10x_test, c10y_test) = cifar10.load_data()\n",
        "\n",
        "c10x_train = c10x_train.reshape(c10x_train.shape[0], 32, 32, 3)\n",
        "c10x_train = c10x_train.astype('float32')\n",
        "\n",
        "c10x_train = preprocess_input(c10x_train)\n",
        "c10x_test = preprocess_input(c10x_test)\n",
        "\n",
        "c10y_train = to_categorical(c10y_train)\n",
        "c10y_test = to_categorical(c10y_test)\n",
        "\n",
        "print('x_train shape:', c10x_train.shape)\n",
        "print(c10x_train.shape[0], 'train samples')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 2s 0us/step\n",
            "x_train shape: (50000, 32, 32, 3)\n",
            "50000 train samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lh65zWfl-UDA"
      },
      "source": [
        "### Importing Train Data From CIFAR100"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-b7A9r_0-UDB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5eb633b6-9a53-46c5-916a-64837b897532"
      },
      "source": [
        "(c100x_train, c100y_train), (c100x_test, c100y_test) = cifar100.load_data()\n",
        "\n",
        "c100x_train = c100x_train.reshape(c100x_train.shape[0], 32, 32, 3)\n",
        "c100x_train = c100x_train.astype('float32')\n",
        "c100x_train /= 255\n",
        "\n",
        "c100y_train = to_categorical(c100y_train)\n",
        "c100y_test = to_categorical(c100y_test)\n",
        "\n",
        "print('x_train shape:', c100x_train.shape)\n",
        "print(c100x_train.shape[0], 'train samples')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
            "169009152/169001437 [==============================] - 2s 0us/step\n",
            "x_train shape: (50000, 32, 32, 3)\n",
            "50000 train samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "em-jW2Dn-UDB"
      },
      "source": [
        "### Importing Train Data From MNIST"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ay8rkgPJ-UDC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "054fba22-963b-4c04-dc47-1d78be8cee14"
      },
      "source": [
        "(mnx_train, mny_train), (mnx_test, mny_test) = mnist.load_data()\n",
        "\n",
        "mnx_train = mnx_train.reshape(mnx_train.shape[0], 28, 28, 1)\n",
        "mnx_train = mnx_train.astype('float32')\n",
        "mnx_train /= 255\n",
        "\n",
        "mny_train = to_categorical(mny_train)\n",
        "mny_test = to_categorical(mny_test)\n",
        "\n",
        "print('x_train shape:', mnx_train.shape)\n",
        "print(mnx_train.shape[0], 'train samples')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "x_train shape: (60000, 28, 28, 1)\n",
            "60000 train samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZLWyZ0Q8-UDC"
      },
      "source": [
        "### Importing Train Data From Fashion MNIST"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h7rLkInl-UDD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fbc7ad95-0361-4301-ceb8-184c890dec15"
      },
      "source": [
        "(fmnx_train, fmny_train), (fmnx_test, fmny_test) = fashion_mnist.load_data()\n",
        "\n",
        "fmnx_train = fmnx_train.reshape(fmnx_train.shape[0], 28, 28, 1)\n",
        "fmnx_train = fmnx_train.astype('float32')\n",
        "fmnx_train /= 255\n",
        "\n",
        "fmny_train = to_categorical(fmny_train)\n",
        "fmny_test = to_categorical(fmny_test)\n",
        "\n",
        "print('x_train shape:', fmnx_train.shape)\n",
        "print(fmnx_train.shape[0], 'train samples')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n",
            "x_train shape: (60000, 28, 28, 1)\n",
            "60000 train samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OcmJqMf2-UDD"
      },
      "source": [
        "### Loading The Dev and Test Set from ImageNet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B_87HqUm-UDE"
      },
      "source": [
        "#### Extracting Images From Website"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_kHuqTu-UDE"
      },
      "source": [
        "def url_to_image(url):\n",
        "    webpage = urllib.request.urlopen(url) # Open the website URL\n",
        "    image = np.asarray(bytearray(webpage.read()), dtype=\"uint8\") # Load the image from the page\n",
        "    image = cv2.imdecode(image, cv2.IMREAD_COLOR) # Decode to a more suitable format\n",
        "    return image # Return the read image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RKdzhm-M-UDE"
      },
      "source": [
        "def get_images(url, n_samples, path):\n",
        "    #Getting the image links and splitting them after converting to sting\n",
        "    page = requests.get(url)\n",
        "    soup = BeautifulSoup(page.content, 'html.parser')\n",
        "    str_soup = str(soup)\n",
        "    \n",
        "    urls = str_soup.split('\\r\\n')\n",
        "    print('No. of URLs is:', len(urls))\n",
        "\n",
        "    #Saving The Train Data\n",
        "    i, count = 0, 0\n",
        "    while 1:\n",
        "        if count % 10 == 0: print('No. of Images Loaded: ', count)\n",
        "        if not urls[i] == None:\n",
        "            try:\n",
        "                img = url_to_image(urls[i])\n",
        "                if (len(img.shape)) == 3:\n",
        "                    save_path = path + str(count) + '.jpg'\n",
        "                    img = cv2.resize(img, (32, 32))\n",
        "                    cv2.imwrite(save_path, img)\n",
        "                    count += 1\n",
        "            except: None\n",
        "\n",
        "        i += 1\n",
        "        if count >= n_samples: break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "B5xgT0gi-UDE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e8acf00-6887-45d6-d1b5-d58ee07e630a"
      },
      "source": [
        "# Cats\n",
        "cats = \"http://www.image-net.org/api/text/imagenet.synset.geturls?wnid=n02123045\"\n",
        "cat_data = '/Users/nmims/Desktop/Semester VI/Deep Learning/Experiment 4/cats/cats'\n",
        "get_images(cats, 0, cat_data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No. of URLs is: 1\n",
            "No. of Images Loaded:  0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "WaSJ0gW7-UDF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8826eaa8-6116-4887-af0e-e2fc369f55a7"
      },
      "source": [
        "# Dogs\n",
        "dogs = \"http://www.image-net.org/api/text/imagenet.synset.geturls?wnid=n02084071\"\n",
        "dog_data = '/Users/nmims/Desktop/Semester VI/Deep Learning/Experiment 4/dogs/dogs'\n",
        "get_images(dogs, 0, dog_data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No. of URLs is: 1\n",
            "No. of Images Loaded:  0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ttzP2Bqr-UDG"
      },
      "source": [
        "#### Loading Images from Stored Folder to Code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EmInYsL3-UDG"
      },
      "source": [
        "def load_images_from_folder(folder):\n",
        "    images = []\n",
        "    for filename in os.listdir(folder):\n",
        "        img = cv2.imread(os.path.join(folder, filename))\n",
        "        if img is not None:\n",
        "            img = cv2.resize(img, (128, 128))\n",
        "            images.append(img)\n",
        "    return images"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WiyLOm4a-UDG"
      },
      "source": [
        "def get_array(folder):\n",
        "    arrays = load_images_from_folder(folder)\n",
        "    print('No of images found in class:', len(arrays))\n",
        "    \n",
        "    images =[]\n",
        "    for i in range(len(arrays)):\n",
        "        arr = arrays[i].reshape((arrays[i].shape[0] * arrays[i].shape[1] * arrays[i].shape[2]))\n",
        "        images = np.append(images, arr)\n",
        "    \n",
        "    images = images.reshape((len(arrays), 128, 128, 3))\n",
        "    return images, len(arrays)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vY4HqYlE-UDH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        },
        "outputId": "d53e41d9-c243-42dd-c2fa-eebaeaa891fd"
      },
      "source": [
        "folder = '/content/Colab/cats'\n",
        "cat, count = get_array(folder)\n",
        "y_temp = np.array([0 for i in range(count)])\n",
        "print('Read Cats')\n",
        "\n",
        "folder = '/content/Colab/dogs'\n",
        "dog, count = get_array(folder)\n",
        "y = np.append(y_temp, np.array([1 for i in range(count)]))\n",
        "print('Read Dogs')\n",
        "\n",
        "x = np.vstack((cat, dog))\n",
        "x = x / 255\n",
        "y = to_categorical(y)\n",
        "print(x.shape)\n",
        "print(y.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-ea8444d36364>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfolder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/Colab/cats'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0my_temp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Read Cats'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-673e5bcd70d0>\u001b[0m in \u001b[0;36mget_array\u001b[0;34m(folder)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0marrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_images_from_folder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'No of images found in class:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-5a6fca5a6114>\u001b[0m in \u001b[0;36mload_images_from_folder\u001b[0;34m(folder)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_images_from_folder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/Colab/cats'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NEs7VOK9-UDJ"
      },
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(x, y, shuffle = True, test_size = 0.5)\n",
        "print(x_train.shape, x_test.shape)\n",
        "print(y_train.shape, y_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q2mzpMnM-UDH"
      },
      "source": [
        "### Visualizing The Train Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qchB8D1P-UDI"
      },
      "source": [
        "fig  = plt.figure(figsize = (10, 7))\n",
        "i = 0\n",
        "for i in range(10):\n",
        "    pl = fig.add_subplot(2, 5, i + 1)\n",
        "    pl.imshow(c100x_train[i], cmap='gray')\n",
        "    i += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8lD9nA1S-UDI"
      },
      "source": [
        "## Model Building"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "US07iPaPlXsM"
      },
      "source": [
        "### VGG16 Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VxAXhsGrladb"
      },
      "source": [
        "def vg_16(params, compilation, input_shape = 32, channel = 3):\n",
        "  vgg16 = VGG16(weights = None, include_top = False, \n",
        "                input_tensor = Input(shape = (input_shape, input_shape, channel)))\n",
        "  # Adding our own output layer to the VGG16 Architecture\n",
        "  out = Sequential()\n",
        "  out.add(Flatten())\n",
        "  out.add(Dense(params['output'], activation = params['activation']))\n",
        "\n",
        "  vgg16 = Model(inputs = vgg16.input, outputs = out(vgg16.output))\n",
        "\n",
        "  vgg16.compile(loss = compilation['loss'], optimizer = compilation['optimizer'], metrics = compilation['metrics'])\n",
        "  return vgg16"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WGsBZKm_bJUH"
      },
      "source": [
        "#### CIFAR10"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AWOIpoKPpDoo"
      },
      "source": [
        "compilation = {'optimizer' : 'adam', 'loss' : 'categorical_crossentropy', \n",
        "               'metrics' : ['accuracy']}\n",
        "params = {'output' : 10, 'activation' : 'softmax'}\n",
        "model = vg_16(params = params, compilation = compilation, input_shape = 32, channel = 3)\n",
        "model.fit(c10x_train, c10y_train, epochs = 10, batch_size = 500)\n",
        "_, acc = model.evaluate(c10x_test, c10y_test)\n",
        "print('The Model accuracy is:', acc * 100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J7kwUZSNb9gl"
      },
      "source": [
        "#### CIFAR100"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7f493pv-cBcJ"
      },
      "source": [
        "compilation = {'optimizer' : 'adam', 'loss' : 'categorical_crossentropy', \n",
        "               'metrics' : ['accuracy']}\n",
        "params = {'output' : 100, 'activation' : 'softmax'}\n",
        "model = vg_16(params = params, compilation = compilation, input_shape = 32, channel = 3)\n",
        "model.fit(c100x_train, c100y_train, epochs = 10, batch_size = 500)\n",
        "\n",
        "_, acc = model.evaluate(c100x_test, c100y_test)\n",
        "print('The Model accuracy on test set:', acc * 100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PodUwDAAeA2_"
      },
      "source": [
        "#### ImageNet Cat-Dog"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QFf-nDBveAhj"
      },
      "source": [
        "compilation = {'optimizer' : 'adam', 'loss' : 'binary_crossentropy', \n",
        "               'metrics' : ['accuracy']}\n",
        "params = {'output' : 2, 'activation' : 'sigmoid'}\n",
        "model = vg_16(params = params, compilation = compilation, input_shape = 128, channel = 3)\n",
        "model.fit(x_train, y_train, epochs = 10, batch_size = 500)\n",
        "\n",
        "_, acc = model.evaluate(x_test, y_test)\n",
        "print('The Model accuracy on test set:', acc * 100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n6oiNGgDg2SV"
      },
      "source": [
        "### VGG19"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hDK4ZGu4g55D"
      },
      "source": [
        "def vg_19(params, compilation, input_shape = 32, channel = 3):\n",
        "  vgg19 = VGG19(weights = None, include_top = False, \n",
        "                input_tensor = Input(shape = (input_shape, input_shape, channel)))\n",
        "  # Adding our own output layer to the VGG19 Architecture\n",
        "  out = Sequential()\n",
        "  out.add(Flatten())\n",
        "  out.add(Dense(params['output'], activation = params['activation']))\n",
        "\n",
        "  vgg19 = Model(inputs = vgg19.input, outputs = out(vgg19.output))\n",
        "\n",
        "  vgg19.compile(loss = compilation['loss'], optimizer = compilation['optimizer'], metrics = compilation['metrics'])\n",
        "  return vgg19"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "npk86CZzhDAC"
      },
      "source": [
        "#### CIFAR10"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TiHY4p9lhGXH"
      },
      "source": [
        "compilation = {'optimizer' : 'rmsprop', 'loss' : 'categorical_crossentropy', \n",
        "               'metrics' : ['accuracy']}\n",
        "params = {'output' : 10, 'activation' : 'softmax'}\n",
        "model = vg_19(params = params, compilation = compilation, input_shape = 32, channel = 3)\n",
        "model.fit(c10x_train, c10y_train, epochs = 10, batch_size = 500)\n",
        "\n",
        "_, acc = model.evaluate(c10x_test, c10y_test)\n",
        "print('The Model accuracy on test set:', acc * 100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "veIvBmiDhCzW"
      },
      "source": [
        "#### CIFAR100"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P66QFiQXhMK3"
      },
      "source": [
        "compilation = {'optimizer' : 'rmsprop', 'loss' : 'categorical_crossentropy', \n",
        "               'metrics' : ['accuracy']}\n",
        "params = {'output' : 100, 'activation' : 'softmax'}\n",
        "model = vg_19(params = params, compilation = compilation, input_shape = 32, channel = 3)\n",
        "model.fit(c100x_train, c100y_train, epochs = 10, batch_size = 500)\n",
        "\n",
        "_, acc = model.evaluate(c100x_test, c100y_test)\n",
        "print('The Model accuracy on test set:', acc * 100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zpxSrE1yhCj9"
      },
      "source": [
        "#### ImageNet Cat-Dog"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AVMqGzObhM7K"
      },
      "source": [
        "compilation = {'optimizer' : 'adam', 'loss' : 'binary_crossentropy', \n",
        "               'metrics' : ['accuracy']}\n",
        "params = {'output' : 2, 'activation' : 'sigmoid'}\n",
        "model = vg_19(params = params, compilation = compilation, input_shape = 128, channel = 3)\n",
        "model.fit(x_train, y_train, epochs = 10, batch_size = 500)\n",
        "\n",
        "_, acc = model.evaluate(x_test, y_test)\n",
        "print('The Model accuracy on test set:', acc * 100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uTZjzwwq-UDL"
      },
      "source": [
        "## Deployment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C9Da9LDz-UDL"
      },
      "source": [
        "!pip install flask-ngrok\n",
        "!pip install flask gevent requests pillow\n",
        "from flask import Flask, render_template, request\n",
        "from flask_ngrok import run_with_ngrok"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L74QgrWu-UDL"
      },
      "source": [
        "procfile = 'web: gunicorn app:app'\n",
        "procfiles= open(\"Procfile\",\"w\")\n",
        "procfiles.write(procfile)\n",
        "procfiles.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "tT9JQgfN-UDM"
      },
      "source": [
        "app = Flask(__name__)\n",
        "run_with_ngrok(app)\n",
        "\n",
        "app.config['UPLOADS'] = 'uploads'\n",
        "\n",
        "def bestModel():\n",
        "    global mymodel\n",
        "    mymodel = load_model('/content/drive/MyDrive/Colab Notebooks/Deep Learning/catDog.h5')\n",
        "\n",
        "@app.route('/')\n",
        "def home():\n",
        "    return render_template('index.html')\n",
        "\n",
        "def predicting(file):\n",
        "    img = cv2.imread(file)\n",
        "    img = cv2.resize(img, (32, 32))\n",
        "    img = np.resize(img, (1, 32, 32, 3)) / 255\n",
        "    pred = mymodel.predict(img)\n",
        "    if pred > 0.5: return 'dog'\n",
        "    else: return 'cat'\n",
        "\n",
        "@app.route('/', methods = ['POST'])\n",
        "def upload_files():\n",
        "    file = request.files['file']\n",
        "    animal = request.form['animal']\n",
        "    for_file = int(animal)\n",
        "    if for_file == 0: animal = 'cat'\n",
        "    else: animal = 'dog'\n",
        "    \n",
        "    filepath = os.path.join(app.config['UPLOADS'], animal, file.filename)\n",
        "    file.save(filepath)\n",
        "    \n",
        "    pred = predicting(filepath)\n",
        "    \n",
        "    # Documentating The Results\n",
        "    doc = pd.read_csv('documentation.csv')\n",
        "    if pred =='cat': out = 0\n",
        "    else: out = 1\n",
        "    doc.loc[len(doc)] = [file.filename, for_file, out]\n",
        "    doc.to_csv('documentation.csv', index = False)\n",
        "    \n",
        "    return render_template('index.html', label = pred)\n",
        "\n",
        "def updateModel():\n",
        "    folder = '/content/uploads/cat'\n",
        "    cat, count = get_array(folder)\n",
        "    y_temp = np.array([0 for i in range(count)])\n",
        "\n",
        "    folder = '/content/uploads/dog'\n",
        "    dog, count = get_array(folder)\n",
        "    y = np.append(y_temp, np.array([1 for i in range(count)]))\n",
        "\n",
        "    x = np.vstack((cat, dog))\n",
        "    x = x / 255\n",
        "    mymodel.fit(x, y, epochs = 10)\n",
        "    # If you want to save the newer version of the model overwriting the previous version\n",
        "    # models.save_model(mymodel, 'catDog.h5')\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    bestModel()\n",
        "    '''\n",
        "    Optional, if we want to retrain the model based on the input it has already saved from uploads\n",
        "    Make sure after training on the upload data, the upload folder is cleared, otherwise it would train on the\n",
        "    the same uploaded data again and again.\n",
        "    '''\n",
        "    # updateModel()\n",
        "    app.run()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CdJkouN070NL"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}