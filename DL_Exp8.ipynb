{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DL-Exp8",
      "provenance": [],
      "authorship_tag": "ABX9TyO1ZGO07/jT3FquVqzY5iCg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rajbhadalia/DL.01/blob/exp1/DL_Exp8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yy-kc6xzaNdV"
      },
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import numpy as np\n",
        "import requests\n",
        "import cv2\n",
        "import PIL.Image\n",
        "import urllib\n",
        "page = requests.get(\"http://www.image-net.org/api/text/imagenet.synset.geturls?wnid=n04194289\")#ship synset\n",
        "print(page.content)\n",
        "# BeautifulSoup is an HTML parsing library\n",
        "soup = BeautifulSoup(page.content, 'html.parser')#puts the content of the website into the soup variable, each url on a different line\n",
        "\n",
        "bikes_page = requests.get(\"http://www.image-net.org/api/text/imagenet.synset.geturls?wnid=n02834778\")#bicycle synset\n",
        "print(bikes_page.content)\n",
        "# BeautifulSoup is an HTML parsing library\n",
        "from bs4 import BeautifulSoup\n",
        "bikes_soup = BeautifulSoup(bikes_page.content, 'html.parser')#puts the content of the website into the soup variable, each url on a different line\n",
        "\n",
        "str_soup=str(soup)#convert soup to string so it can be split\n",
        "type(str_soup)\n",
        "split_urls=str_soup.split('\\r\\n')#split so each url is a different possition on a list\n",
        "print(len(split_urls))#print the length of the list so you know how many urls you have\n",
        "\n",
        "bikes_str_soup=str(bikes_soup)#convert soup to string so it can be split\n",
        "type(bikes_str_soup)\n",
        "bikes_split_urls=bikes_str_soup.split('\\r\\n')#split so each url is a different possition on a list\n",
        "print(len(bikes_split_urls))\n",
        "\n",
        "!mkdir /content/train #create the Train folder\n",
        "!mkdir /content/train/ships #create the ships folder\n",
        "!mkdir /content/train/bikes #create the bikes folder\n",
        "!mkdir /content/validation\n",
        "!mkdir /content/validation/ships #create the ships folder\n",
        "!mkdir /content/validation/bikes #create the bikes folder\n",
        "\n",
        "#code part 4\n",
        "img_rows, img_cols = 32, 32 #number of rows and columns to convert the images to\n",
        "input_shape = (img_rows, img_cols, 3)#format to store the images (rows, columns,channels) called channels last\n",
        "\n",
        "def url_to_image(url):\n",
        "\t# download the image, convert it to a NumPy array, and then read\n",
        "\t# it into OpenCV format\n",
        "\tresp = urllib.request.urlopen(url)\n",
        "\timage = np.asarray(bytearray(resp.read()), dtype=\"uint8\")\n",
        "\timage = cv2.imdecode(image, cv2.IMREAD_COLOR)\n",
        " \n",
        "\t# return the image\n",
        "\treturn image\n",
        "\n",
        "n_of_training_images=100#the number of training images to use\n",
        "for progress in range(n_of_training_images):#store all the images on a directory\n",
        "    # Print out progress whenever progress is a multiple of 20 so we can follow the\n",
        "    # (relatively slow) progress\n",
        "    if(progress%20==0):\n",
        "        print(progress)\n",
        "    if not split_urls[progress] == None:\n",
        "      try:\n",
        "        I = url_to_image(split_urls[progress])\n",
        "        if (len(I.shape))==3: #check if the image has width, length and channels\n",
        "          save_path = '/content/train/ships/img'+str(progress)+'.jpg'#create a name of each image\n",
        "          cv2.imwrite(save_path,I)\n",
        "\n",
        "      except:\n",
        "        None\n",
        "\n",
        "#do the same for bikes:\n",
        "for progress in range(n_of_training_images):#store all the images on a directory\n",
        "    # Print out progress whenever progress is a multiple of 20 so we can follow the\n",
        "    # (relatively slow) progress\n",
        "    if(progress%20==0):\n",
        "        print(progress)\n",
        "    if not bikes_split_urls[progress] == None:\n",
        "      try:\n",
        "        I = url_to_image(bikes_split_urls[progress])\n",
        "        if (len(I.shape))==3: #check if the image has width, length and channels\n",
        "          save_path = '/content/train/bikes/img'+str(progress)+'.jpg'#create a name of each image\n",
        "          cv2.imwrite(save_path,I)\n",
        "\n",
        "      except:\n",
        "        None\n",
        "        \n",
        "        \n",
        "#Validation data:\n",
        "\n",
        "for progress in range(50):#store all the images on a directory\n",
        "    # Print out progress whenever progress is a multiple of 20 so we can follow the\n",
        "    # (relatively slow) progress\n",
        "    if(progress%20==0):\n",
        "        print(progress)\n",
        "    if not split_urls[progress] == None:\n",
        "      try:\n",
        "        I = url_to_image(split_urls[n_of_training_images+progress])#get images that are different from the ones used for training\n",
        "        if (len(I.shape))==3: #check if the image has width, length and channels\n",
        "          save_path = '/content/validation/ships/img'+str(progress)+'.jpg'#create a name of each image\n",
        "          cv2.imwrite(save_path,I)\n",
        "\n",
        "      except:\n",
        "        None\n",
        "\n",
        "#do the same for bikes:\n",
        "for progress in range(50):#store all the images on a directory\n",
        "    # Print out progress whenever progress is a multiple of 20 so we can follow the\n",
        "    # (relatively slow) progress\n",
        "    if(progress%20==0):\n",
        "        print(progress)\n",
        "    if not bikes_split_urls[progress] == None:\n",
        "      try:\n",
        "        I = url_to_image(bikes_split_urls[n_of_training_images+progress])#get images that are different from the ones used for training\n",
        "        if (len(I.shape))==3: #check if the image has width, length and channels\n",
        "          save_path = '/content/validation/bikes/img'+str(progress)+'.jpg'#create a name of each image\n",
        "          cv2.imwrite(save_path,I)\n",
        "\n",
        "      except:\n",
        "        None\n",
        "        \n",
        "print(\"\\nTRAIN:\\n\")          \n",
        "print(\"\\nlist the files inside ships directory:\\n\")        \n",
        "!ls /content/train/ships #list the files inside ships\n",
        "print(\"\\nlist the files inside bikes directory:\\n\")\n",
        "!ls /content/train/bikes #list the files inside bikes\n",
        "print(\"\\nVALIDATION:\\n\")\n",
        "print(\"\\nlist the files inside ships directory:\\n\")        \n",
        "!ls /content/validation/ships #list the files inside ships\n",
        "print(\"\\nlist the files inside bikes directory:\\n\")\n",
        "!ls /content/validation/bikes #list the files inside bikes   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QH9Og-1cOYIJ"
      },
      "source": [
        "import cv2                  \n",
        "import numpy as np  \n",
        "from tqdm import tqdm\n",
        "import os                   \n",
        "from random import shuffle  \n",
        "from zipfile import ZipFile\n",
        "from PIL import Image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JD8FryeiNLk5"
      },
      "source": [
        "X = []\n",
        "y = []\n",
        "train_bikes = '/content/train/bikes'\n",
        "train_ships = '/content/train/ships'\n",
        "val_bikes = '/content/validation/bikes'\n",
        "val_ships = '/content/validation/ships'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FDsEMwTNNmwv"
      },
      "source": [
        "def assign_label(img,flower_type):\n",
        "    return flower_type\n",
        "\n",
        "def make_train_data(flower_type,DIR):\n",
        "    for img in tqdm(os.listdir(DIR)):\n",
        "        label=assign_label(img,flower_type)\n",
        "        path = os.path.join(DIR,img)\n",
        "        img = cv2.imread(path,cv2.IMREAD_COLOR)   \n",
        "        img = cv2.resize(img, (32,32))        \n",
        "        X.append(np.array(img))\n",
        "        y.append(str(label))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HsXnm5j6NwCA"
      },
      "source": [
        "make_train_data('bikes', train_bikes)\n",
        "make_train_data('ships', train_ships)\n",
        "make_train_data('bikes', val_bikes)\n",
        "make_train_data('ships', val_ships)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bg3jujj9OayP"
      },
      "source": [
        "len(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p0gyj11iAKFh"
      },
      "source": [
        "X[0].shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ta5t_Bh0OhBN"
      },
      "source": [
        "len(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OCNsvnTwOi79"
      },
      "source": [
        "Xarray = np.asarray(X).astype('float32')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_4SgAnmO7cZ"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gG9xo3r8Ory9"
      },
      "source": [
        "le=LabelEncoder()\n",
        "Y=le.fit_transform(y)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sv_I10-qPF_9"
      },
      "source": [
        "Y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eays_SD_O82d"
      },
      "source": [
        "Xarray=Xarray/255.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lJDr2rD3O_St"
      },
      "source": [
        "Xarray[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_bPV24tYPL-u"
      },
      "source": [
        "Xarray.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kob35S3qLlxx"
      },
      "source": [
        "import numpy as np\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dropout, Flatten, Dense\n",
        "from keras import applications\n",
        "from keras.layers import Input"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NoMSnWdOMYyO"
      },
      "source": [
        "model = applications.VGG16(include_top=False, weights='imagenet', input_tensor=Input(shape=(32,32,3)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-UOQsjVKBhVu"
      },
      "source": [
        "#Passing VGG16 through input"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_5Nd1Cj7M3nI"
      },
      "source": [
        "bottleneck_features = model(Xarray)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "igIE0b66BaLp"
      },
      "source": [
        "bottleneck_features.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0xJQJoJ09_MK"
      },
      "source": [
        "#Second part"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fwEOFPSC-BGh"
      },
      "source": [
        "newmodel = Sequential()\n",
        "newmodel.add(Flatten(input_shape=(bottleneck_features.shape[1:])))\n",
        "newmodel.add(Dense(units=128, activation='relu'))\n",
        "newmodel.add(Dense(units=1, activation='sigmoid'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "43ibCfE0CoIT"
      },
      "source": [
        "newmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M9ZXGz4mC5Pw"
      },
      "source": [
        "newmodel.fit(x=bottleneck_features, y=Y, validation_split=0.2, epochs=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xfv8GXPrFE92"
      },
      "source": [
        "#Fine tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xDHRWMh9GGJg"
      },
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Input\n",
        "# build the VGG16 network\n",
        "\n",
        "input_tensor = Input(shape=(32,32,3))\n",
        "base_model = applications.VGG16(weights='imagenet',include_top= False,input_tensor=input_tensor)\n",
        "\n",
        "top_model = Sequential()\n",
        "top_model.add(Flatten(input_shape=base_model.output_shape[1:]))\n",
        "top_model.add(Dense(256, activation='relu'))\n",
        "top_model.add(Dropout(0.5))\n",
        "top_model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "\n",
        "\n",
        "model = Model(inputs= base_model.input, outputs= top_model(base_model.output))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQDG0dTxGfxh"
      },
      "source": [
        "base_model.layers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "apZvpwa3Gw5s"
      },
      "source": [
        "top_model.layers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L-cEasUoHDj1"
      },
      "source": [
        "#Freeze base model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tuJUlrlCHGfE"
      },
      "source": [
        "for layer in base_model.layers:\n",
        "    layer.trainable = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WOD-DSpTJXWv"
      },
      "source": [
        "#Freeze first few layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vwFaX4wRJaDv"
      },
      "source": [
        "for layer in base_model.layers[:10]:\n",
        "    layer.trainable = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WkM8GZjvIJpk"
      },
      "source": [
        "# compile the model with a SGD/momentum optimizer\n",
        "# and a very slow learning rate."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ZqrYX8EIUl2"
      },
      "source": [
        "import keras"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qLr5ZcVqHaRk"
      },
      "source": [
        "model.compile(optimizer=keras.optimizers.SGD(lr=1e-4, momentum=0.9), loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YFbrAx_QH9ia"
      },
      "source": [
        "#Verify if base model is frozen"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EohXjd8yHo84"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CjC9F9X8IsSU"
      },
      "source": [
        "#Train the integrated model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGKl9l7VIwK8"
      },
      "source": [
        "model.fit(x=Xarray, y=Y, epochs=10, validation_split=0.2)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}